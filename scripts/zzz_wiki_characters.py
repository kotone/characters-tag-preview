"""
ç»åŒºé›¶ Wiki API - è·å–è§’è‰²åˆ—è¡¨ï¼ˆä¸­è‹±æ–‡åˆå¹¶ï¼‰
ä» HoYoLAB Wiki API è·å–ç»åŒºé›¶æ‰€æœ‰è§’è‰²çš„ä¸­è‹±æ–‡ä¿¡æ¯
"""

import requests
import json
import time
import os
from typing import List, Dict, Optional


class ZZZWikiAPI:
    """ç»åŒºé›¶ Wiki API å®¢æˆ·ç«¯"""
    
    BASE_URL = "https://sg-wiki-api.hoyolab.com/hoyowiki/zzz/wapi"
    
    # ç²¾ç®€çš„è¯·æ±‚å¤´é…ç½®
    DEFAULT_HEADERS = {
        "accept": "application/json, text/plain, */*",
        "accept-language": "zh-CN,zh;q=0.9,en;q=0.8",
        "content-type": "application/json;charset=UTF-8",
        "referer": "https://wiki.hoyolab.com/",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36",
        # HoYoLAB API å¿…éœ€çš„header
        "x-rpc-language": "zh-cn",
        "x-rpc-wiki_app": "zzz"
    }
    
    def __init__(self, timeout: int = 10):
        self.timeout = timeout
    
    def get_character_list(self, language: str = "zh-cn", page_size: int = 30) -> List[Dict]:
        """
        è·å–è§’è‰²åˆ—è¡¨
        
        Args:
            language: è¯­è¨€ä»£ç  ("zh-cn" ä¸­æ–‡, "en-us" è‹±æ–‡)
            page_size: æ¯é¡µæ•°é‡
        
        Returns:
            è§’è‰²åˆ—è¡¨
        """
        url = f"{self.BASE_URL}/get_entry_page_list"
        
        # æ›´æ–°è¯­è¨€ header
        headers = self.DEFAULT_HEADERS.copy()
        headers["x-rpc-language"] = language
        
        all_characters = []
        page_num = 1
        
        while True:
            payload = {
                "filters": [],
                "menu_id": "8",  # ç»åŒºé›¶è§’è‰²èœå•ID
                "page_num": page_num,
                "page_size": page_size,
                "use_es": True
            }
            
            try:
                response = requests.post(
                    url,
                    json=payload,
                    headers=headers,
                    timeout=self.timeout
                )
                
                if response.status_code != 200:
                    print(f"âŒ HTTP é”™è¯¯: {response.status_code}")
                    break
                
                data = response.json()
                
                if data.get('retcode') != 0:
                    print(f"âŒ API è¿”å›é”™è¯¯: retcode={data.get('retcode')}, message={data.get('message')}")
                    break
                
                # æå–è§’è‰²åˆ—è¡¨
                page_data = data.get('data', {})
                characters = page_data.get('list', [])
                total = int(page_data.get('total', 0))  # ç¡®ä¿æ˜¯æ•´æ•°
                
                if not characters:
                    break
                
                all_characters.extend(characters)
                
                print(f"ğŸ“¥ å·²è·å– {len(all_characters)}/{total} ä¸ªè§’è‰² (è¯­è¨€: {language})")
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæ•°æ®
                if len(all_characters) >= total:
                    break
                
                page_num += 1
                time.sleep(0.5)  # é¿å…è¯·æ±‚è¿‡å¿«
                
            except Exception as e:
                print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
                break
        
        return all_characters
    
    def merge_character_data(self, cn_list: List[Dict], en_list: List[Dict]) -> List[Dict]:
        """
        åˆå¹¶ä¸­è‹±æ–‡è§’è‰²æ•°æ®
        
        Args:
            cn_list: ä¸­æ–‡è§’è‰²åˆ—è¡¨
            en_list: è‹±æ–‡è§’è‰²åˆ—è¡¨
        
        Returns:
            åˆå¹¶åçš„è§’è‰²åˆ—è¡¨ï¼ŒåªåŒ…å«å…³é”®å­—æ®µ
        """
        # ä½¿ç”¨ entry_page_id ä½œä¸ºå”¯ä¸€æ ‡è¯†å»ºç«‹æ˜ å°„
        en_map = {char.get('entry_page_id'): char for char in en_list}
        
        merged = []
        
        for cn_char in cn_list:
            entry_id = cn_char.get('entry_page_id')
            en_char = en_map.get(entry_id, {})
            
            # è·å–è‹±æ–‡åå¹¶ç”Ÿæˆtag
            name_en = en_char.get('name', '')
            # å°†è‹±æ–‡åè½¬ä¸ºtagæ ¼å¼ï¼šå°å†™ï¼Œç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦è½¬ä¸ºä¸‹åˆ’çº¿
            tag_name = name_en.lower().replace(' ', '_').replace('-', '_').replace('â€¢', '_')
            # ç§»é™¤å¤šä½™ä¸‹åˆ’çº¿
            tag_name = '_'.join(filter(None, tag_name.split('_')))
            
            # åªä¿ç•™å¿…è¦å­—æ®µ
            merged_char = {
                'entry_page_id': entry_id,
                'name_cn': cn_char.get('name', ''),
                'name_en': name_en,
                'tag': f"{tag_name}_(zenless_zone_zero)" if tag_name else '',
                'source': 'zenless_zone_zero',
                'source_cn': 'ç»åŒºé›¶',
                'icon_url': cn_char.get('icon_url', ''),
                'header_img_url': cn_char.get('header_img_url', '')
            }
            
            merged.append(merged_char)
        
        return merged
    
    def get_merged_character_list(self) -> List[Dict]:
        """
        è·å–ä¸­è‹±æ–‡åˆå¹¶çš„è§’è‰²åˆ—è¡¨
        
        Returns:
            åˆå¹¶åçš„è§’è‰²åˆ—è¡¨
        """
        print("=" * 60)
        print("ğŸ“š å¼€å§‹è·å–ç»åŒºé›¶è§’è‰²åˆ—è¡¨...")
        print("=" * 60)
        
        # è·å–ä¸­æ–‡åˆ—è¡¨
        print("\n1ï¸âƒ£ è·å–ä¸­æ–‡è§’è‰²åˆ—è¡¨...")
        cn_list = self.get_character_list(language="zh-cn")
        
        # è·å–è‹±æ–‡åˆ—è¡¨
        print("\n2ï¸âƒ£ è·å–è‹±æ–‡è§’è‰²åˆ—è¡¨...")
        en_list = self.get_character_list(language="en-us")
        
        # åˆå¹¶æ•°æ®
        print("\n3ï¸âƒ£ åˆå¹¶ä¸­è‹±æ–‡æ•°æ®...")
        merged = self.merge_character_data(cn_list, en_list)
        
        print(f"\nâœ… åˆå¹¶å®Œæˆï¼å…± {len(merged)} ä¸ªè§’è‰²")
        
        return merged


def main():
    """ä¸»å‡½æ•°"""
    
    # åˆ›å»º API å®¢æˆ·ç«¯
    api = ZZZWikiAPI()
    
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    # é¡¹ç›®æ ¹ç›®å½•ï¼šå‘ä¸Šä¸€çº§åˆ° characters-tag-preview/
    project_root = os.path.normpath(os.path.join(script_dir, '..'))
    # output æ–‡ä»¶å¤¹åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹
    output_dir = os.path.join(project_root, 'output')
    
    # ç¡®ä¿ output ç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    print("=" * 60)
    print("ğŸ“š å¼€å§‹è·å–ç»åŒºé›¶è§’è‰²åˆ—è¡¨...")
    print("=" * 60)
    
    # è·å–ä¸­æ–‡åˆ—è¡¨
    print("\n1ï¸âƒ£ è·å–ä¸­æ–‡è§’è‰²åˆ—è¡¨...")
    cn_list = api.get_character_list(language="zh-cn")
    
    # è·å–è‹±æ–‡åˆ—è¡¨
    print("\n2ï¸âƒ£ è·å–è‹±æ–‡è§’è‰²åˆ—è¡¨...")
    en_list = api.get_character_list(language="en-us")
    
    # åˆå¹¶æ•°æ®
    print("\n3ï¸âƒ£ åˆå¹¶ä¸­è‹±æ–‡æ•°æ®...")
    merged_list = api.merge_character_data(cn_list, en_list)
    
    print(f"\nâœ… åˆå¹¶å®Œæˆï¼å…± {len(merged_list)} ä¸ªè§’è‰²")
    
    # ä¿å­˜åˆå¹¶æ•°æ®åˆ° output æ–‡ä»¶å¤¹
    print("\nğŸ’¾ ä¿å­˜æ•°æ®...")
    
    output_file = os.path.join(output_dir, 'zzz_characters-en-cn.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(merged_list, f, ensure_ascii=False, indent=2)
    print(f"âœ… å·²ä¿å­˜: {os.path.basename(output_file)} ({len(merged_list)} ä¸ªè§’è‰²)")
    
    # æ˜¾ç¤ºéƒ¨åˆ†æ•°æ®ç¤ºä¾‹
    print("\n" + "=" * 60)
    print("ğŸ“Š è§’è‰²åˆ—è¡¨ç¤ºä¾‹ï¼ˆå‰ 5 ä¸ªï¼‰:")
    print("=" * 60)
    
    for i, char in enumerate(merged_list[:5], 1):
        print(f"\nã€{i}ã€‘ {char['name_cn']} ({char['name_en']})")
        print(f"  ID: {char['entry_page_id']}")
        print(f"  Tag: {char['tag']}")
        if char.get('icon_url'):
            print(f"  å¤´åƒ: {char['icon_url'][:60]}...")
    
    print("\n" + "=" * 60)
    print(f"âœ¨ å®Œæˆï¼æ•°æ®å·²ä¿å­˜è‡³: {output_file}")
    print("=" * 60)


if __name__ == '__main__':
    main()
